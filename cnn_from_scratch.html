<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>297929</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section id="convolutional-neural-networks" class="cell markdown" id="wkPUrtCOt7fB">
<h1>Convolutional Neural Networks</h1>
<h2 id="project-write-an-algorithm-for-landmark-classification">Project: Write an Algorithm for Landmark Classification</h2>
<h3 id="introduction">Introduction</h3>
<p>The project folder has the following structure:</p>
<ul>
<li><p>In the main directory you have this notebook, <code>cnn_from_scratch.ipynb</code>, that contains the instruction and some questions you will have to answer. Follow this notebook and complete the required sections in order.</p></li>
<li><p>In the <code>src/</code> directory you have several source files. As instructed in this notebook, you will open and complete those files, then come back to this notebook to execute some tests that will verify what you have done. While these tests don't guarantee that your work is bug-free, they will help you finding the most obvious problems so you will be able to proceed to the next step with confidence.</p></li>
<li><p>Sometimes you will need to restart the notebook. If you do so, remember to execute also the cells containing the code you have already completed starting from the top, before you move on.</p></li>
</ul>
<blockquote>
<p><img src="https://github.com/John0Isaac/Landmark-Classification-Tagging-for-Social-Media/blob/main/static_images/icons/noun-info-2558213.png?raw=1" alt="?" style="width:25px"/> Once you have completed all the code implementations, you need to finalize your work by exporting the Jupyter Notebook as an HTML document. Before exporting the notebook to HTML, all the code cells need to have been run so that reviewers can see the final implementation and output. You can then export the notebook by using the menu above and navigating to <strong>File -&gt; Download as -&gt; HTML (.html)</strong>. If you are using Jupyter Lab, you can use <strong>File -&gt; Export Notebook as -&gt; Export Notebook to HTML</strong>. Include the finished document along with this notebook as your submission.</p>
</blockquote>
<p>In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a <strong>'Question'</strong> header. Carefully read each question and provide thorough answers in the following text boxes that begin with <strong>'Answer:'</strong>. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.</p>
<blockquote>
<p><img src="https://github.com/John0Isaac/Landmark-Classification-Tagging-for-Social-Media/blob/main/static_images/icons/noun-info-2558213.png?raw=1" alt="?" style="width:25px"/> Code and Markdown cells can be executed using the <strong>Shift + Enter</strong> keyboard shortcut. Markdown cells can be edited by double-clicking the cell to enter edit mode.</p>
</blockquote>
<p>The rubric contains <em>optional</em> "Stand Out Suggestions" for enhancing the project beyond the minimum requirements. If you decide to pursue the "Stand Out Suggestions", you should include the code in this Jupyter notebook.</p>
<h3 id="designing-and-training-a-cnn-from-scratch">Designing and training a CNN from scratch</h3>
<p>In this notebook, you will create a CNN that classifies landmarks. You must create your CNN <em>from scratch</em> (so, you can't use transfer learning <em>yet</em>!), and you must attain a test accuracy of at least 50%.</p>
<p>Although 50% may seem low at first glance, it seems more reasonable after realizing how difficult of a problem this is. Many times, an image that is taken at a landmark captures a fairly mundane image of an animal or plant, like in the following picture.</p>
<p><img src="https://github.com/John0Isaac/Landmark-Classification-Tagging-for-Social-Media/blob/main/static_images/train/00.Haleakala_National_Park/084c2aa50d0a9249.jpg?raw=1" alt="Bird in Haleakalā National Park" style="width: 400px;"/></p>
<p>Just by looking at that image alone, would you have been able to guess that it was taken at the Haleakalā National Park in Hawaii?</p>
<p>An accuracy of 50% is significantly better than random guessing, which would provide an accuracy of just 2% (100% / 50 classes). In Step 2 of this notebook, you will have the opportunity to greatly improve accuracy by using transfer learning to create a CNN.</p>
<p>Experiment with different architectures, hyperparameters, training strategies, and trust your intuition. And, of course, have fun!</p>
<hr />
<h2 id="-stylewidth50px-step-0-setting-up"><img src="https://github.com/John0Isaac/Landmark-Classification-Tagging-for-Social-Media/blob/main/static_images/icons/noun-advance-2109145.png?raw=1" alt=">" style="width:50px"/&gt; Step 0: Setting up</h2>
<p>The following cells make sure that your environment is setup correctly, download the data if you don't have it already, and also check that your GPU is available and ready to go. You have to execute them every time you restart your notebook.</p>
</section>
<div class="cell code" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}" id="7XpRwfaNt7fH" data-outputId="48d781b5-beba-40eb-af5e-479b603f1647" data-tags="[]">
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install requirements</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>r requirements.txt <span class="op">|</span> grep <span class="op">-</span>v <span class="st">&quot;already satisfied&quot;</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Defaulting to user installation because normal site-packages is not writeable

[notice] A new release of pip is available: 23.0.1 -&gt; 23.1.2
[notice] To update, run: pip install --upgrade pip
</code></pre>
</div>
</div>
<div class="cell code" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="ftQ_-w_nt7fJ" data-outputId="2d131630-fb61-4f38-b9f8-1535c513a05f" data-tags="[]">
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.helpers <span class="im">import</span> setup_env</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># If running locally, this will download dataset (make sure you have at </span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># least 2 Gb of space on your hard drive)</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>setup_env()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>GPU available
Downloading and unzipping https://udacity-dlnfd.s3-us-west-1.amazonaws.com/datasets/landmark_images.zip. This will take a while...
done
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>Computing mean: 100%|███████████████████████| 6246/6246 [01:30&lt;00:00, 68.94it/s]
Computing std: 100%|████████████████████████| 6246/6246 [01:39&lt;00:00, 62.55it/s]
</code></pre>
</div>
</div>
<div class="cell markdown" id="ccWiNZu4t7fK">
<hr />
<h2 id="-stylewidth50px-step-1-data"><img src="https://github.com/John0Isaac/Landmark-Classification-Tagging-for-Social-Media/blob/main/static_images/icons/noun-advance-2109145.png?raw=1" alt=">" style="width:50px"/&gt; Step 1: Data</h2>
<p>In this and the following steps we are going to complete some code, and then execute some tests to make sure the code works as intended.</p>
<p>Open the file <code>src/data.py</code>. It contains a function called <code>get_data_loaders</code>. Read the function and complete all the parts marked by <code>YOUR CODE HERE</code>. Once you have finished, test that your implementation is correct by executing the following cell (see below for what to do if a test fails):</p>
</div>
<div class="cell code" id="3nT4Q7art7fK" data-outputId="b947a737-761a-4774-bf7f-8d5ca39f3cc0">
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pytest <span class="op">-</span>vv src<span class="op">/</span>data.py <span class="op">-</span>k data_loaders</span></code></pre></div>
<div class="output stream stdout">
<pre><code>============================= test session starts ==============================
platform linux -- Python 3.7.17, pytest-7.3.2, pluggy-1.0.0 -- /usr/local/bin/python
cachedir: .pytest_cache
rootdir: /workspaces/Landmark-Classification-Tagging-for-Social-Media
plugins: anyio-3.7.0
collected 4 items / 1 deselected / 3 selected                                  

src/data.py::test_data_loaders_keys PASSED                               [ 33%]
src/data.py::test_data_loaders_output_type PASSED                        [ 66%]
src/data.py::test_data_loaders_output_shape PASSED                       [100%]

======================= 3 passed, 1 deselected in 1.42s ========================
</code></pre>
</div>
</div>
<div class="cell markdown" id="yHAU2N3wt7fL">
<p>You should see something like:</p>
<pre><code>src/data.py::test_data_loaders_keys PASSED                               [ 33%]
src/data.py::test_data_loaders_output_type PASSED                        [ 66%]
src/data.py::test_data_loaders_output_shape PASSED                       [100%]

======================= 3 passed, 1 deselected in 1.81s ========================</code></pre>
<p>If all the tests are <code>PASSED</code>, you can move to the next section.</p>
<blockquote>
<p><img src="https://github.com/John0Isaac/Landmark-Classification-Tagging-for-Social-Media/blob/main/static_images/icons/noun-info-2558213.png?raw=1" alt="?" style="width:25px"/> <strong>What to do if tests fail</strong> When a test fails, <code>pytest</code> will mark it as <code>FAILED</code> as opposed to <code>PASSED</code>, and will print a lot of useful output, including a message that should tell you what the problem is. For example, this is the output of a failed test:</p>
<pre><code>   def test_data_loaders_keys(data_loaders):
   
      assert set(data_loaders.keys()) == {&quot;train&quot;, &quot;valid&quot;, &quot;test&quot;}
E       AssertionError: assert {&#39;tes&#39;, &#39;train&#39;, &#39;valid&#39;} == {&#39;test&#39;, &#39;train&#39;, &#39;valid&#39;}
E         Extra items in the left set:
E         &#39;tes&#39;
E         Full diff:
E         - {&#39;test&#39;, &#39;train&#39;, &#39;valid&#39;}
E         + {&#39;tes&#39;, &#39;train&#39;, &#39;valid&#39;}
E         ?                          +++++++

src/data.py:171: AssertionError
-------------- Captured stdout setup ----------------------------------------------
Reusing cached mean and std for landmark_images
Dataset mean: tensor([0.4638, 0.4725, 0.4687]), std: tensor([0.2699, 0.2706, 0.3018])
=========== short test summary info ===============================================
FAILED src/data.py::test_data_loaders_keys - AssertionError: The keys of the data_loaders dictionary should be train, valid and test</code></pre>
<p>In the <code>short test summary info</code> you can see a short description of the problem. In this case, the dictionary we are returning has the wrong keys. Going above a little, you can see that the test expects <code>{'test', 'train', 'valid'}</code> while we are returning <code>{'tes', 'train', 'valid'}</code> (there is a missing <code>t</code>). So we can go back to our function, fix that problem and test again.</p>
<p>In other cases, you might get an error like:</p>
<pre><code>def _conv_forward(self, input: Tensor, weight: Tensor, bias: Optional[Tensor]):
if self.padding_mode != &#39;zeros&#39;:
return F.conv2d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),
weight, bias, self.stride,
_pair(0), self.dilation, self.groups)
return F.conv2d(input, weight, bias, self.stride,
                      self.padding, self.dilation, self.groups)
E       RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same

../../../../miniconda3/envs/udacity_starter/lib/python3.7/site-packages/torch/nn/modules/conv.py:440: RuntimeError</code></pre>
<p>Looking at the stack trace you should be able to understand what it is going on. In this case, we forgot to add a <code>.cuda()</code> to some tensor. For example, the model is on the GPU, but the data aren't.</p>
</blockquote>
</div>
<div class="cell markdown" id="4ErYm1sSt7fL">
<p><img src="https://github.com/John0Isaac/Landmark-Classification-Tagging-for-Social-Media/blob/main/static_images/icons/noun-question-mark-869751.png?raw=1" alt="?" style="width:25px"/> <strong>Question:</strong> Describe your chosen procedure for preprocessing the data.</p>
<ul>
<li>How does your code resize the images (by cropping, stretching, etc)? What size did you pick for the input tensor, and why?</li>
<li>Did you decide to augment the dataset? If so, how (through translations, flips, rotations, etc)? If not, why not?</li>
</ul>
</div>
<div class="cell markdown" id="EmVMdNZit7fM">
<p><img src="https://github.com/John0Isaac/Landmark-Classification-Tagging-for-Social-Media/blob/main/static_images/icons/noun-answer-3361020.png?raw=1" alt=">" style="width:25px"/&gt; <strong>Answer</strong>: My code first resizes the image to 256 and then crops to 224. I picked 224 as the input size because it is the recommended input size for using pytorch's pre-trained models. I did decide to augment the dataset via RandAugment, a typical set of augmentations for natural images. I added this augmentation with the goal of improving my model's robustness, thus improving test accuracy.</p>
</div>
<section id="visualize-a-batch-of-training-data" class="cell markdown" id="WeTQuyl4t7fM">
<h3>Visualize a Batch of Training Data</h3>
<p>Go back to <code>src/data.py</code> and complete the function <code>visualize_one_batch</code> in all places with the <code>YOUR CODE HERE</code> marker. After you're done, execute the following cell and make sure the test <code>src/data.py::test_visualize_one_batch</code> is <code>PASSED</code>:</p>
</section>
<div class="cell code" id="pphfuRtit7fN" data-outputId="63928e1c-abdc-4bb4-aac7-bddd2aae0277">
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pytest <span class="op">-</span>vv src<span class="op">/</span>data.py <span class="op">-</span>k visualize_one_batch</span></code></pre></div>
<div class="output stream stdout">
<pre><code>============================= test session starts ==============================
platform linux -- Python 3.7.17, pytest-7.3.2, pluggy-1.0.0 -- /usr/local/bin/python
cachedir: .pytest_cache
rootdir: /workspaces/Landmark-Classification-Tagging-for-Social-Media
plugins: anyio-3.7.0
collected 4 items / 3 deselected / 1 selected                                  

src/data.py::test_visualize_one_batch PASSED                             [100%]

======================= 1 passed, 3 deselected in 1.71s ========================
</code></pre>
</div>
</div>
<div class="cell markdown" id="Rv8ZyLryt7fN">
<p>We can now use the code we just completed to get a batch of images from your train data loader and look at them.</p>
<p>Visualizing the output of your data loader is a great way to ensure that your data loading and preprocessing (including transforms such as rotations, translations, color transforms...) are working as expected.</p>
</div>
<div class="cell code" id="5dJi3uFBt7fO" data-outputId="afb60c18-a55b-4c76-d705-5ce91c488947">
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.data <span class="im">import</span> visualize_one_batch, get_data_loaders</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># use get_data_loaders to get the data_loaders dictionary. Use a batch_size</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co"># of 5, a validation size of 0.01 and num_workers=-1 (all CPUs)</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>data_loaders <span class="op">=</span> get_data_loaders(batch_size<span class="op">=</span><span class="dv">5</span>, valid_size<span class="op">=</span><span class="fl">0.01</span>, num_workers<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>visualize_one_batch(data_loaders)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Reusing cached mean and std
Dataset mean: tensor([0.4638, 0.4725, 0.4687]), std: tensor([0.2697, 0.2706, 0.3017])
Reusing cached mean and std
</code></pre>
</div>
<div class="output display_data">
<p><img src="deb9d01845310a8bd3d5bd3bb94baa9edcc89783.png" /></p>
</div>
</div>
<div class="cell markdown" id="g_P7dHXht7fO">
<hr />
<h2 id="-stylewidth50px-step-2-define-model"><img src="https://github.com/John0Isaac/Landmark-Classification-Tagging-for-Social-Media/blob/main/static_images/icons/noun-advance-2109145.png?raw=1" alt=">" style="width:50px"/&gt; Step 2: Define model</h2>
<p>Open <code>src/model.py</code> and complete the <code>MyModel</code> class filling in all the <code>YOUR CODE HERE</code> sections. After you're done, execute the following test and make sure it passes:</p>
</div>
<div class="cell code" id="eywdqHFNt7fP" data-outputId="edfeb521-6b8b-4417-cd7a-c2f387738b02">
<div class="sourceCode" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pytest <span class="op">-</span>vv src<span class="op">/</span>model.py</span></code></pre></div>
<div class="output stream stdout">
<pre><code>============================= test session starts ==============================
platform linux -- Python 3.7.17, pytest-7.3.2, pluggy-1.0.0 -- /usr/local/bin/python
cachedir: .pytest_cache
rootdir: /workspaces/Landmark-Classification-Tagging-for-Social-Media
plugins: anyio-3.7.0
collected 1 item                                                               

src/model.py::test_model_construction PASSED                             [100%]

============================== 1 passed in 1.59s ===============================
</code></pre>
</div>
</div>
<div class="cell markdown" id="YRrEw8wxt7fP">
<p><img src="https://github.com/John0Isaac/Landmark-Classification-Tagging-for-Social-Media/blob/main/static_images/icons/noun-question-mark-869751.png?raw=1" alt="?" style="width:25px"/> <strong>Question</strong>: Outline the steps you took to get to your final CNN architecture and your reasoning at each step.</p>
</div>
<div class="cell markdown" id="44MMQW5Gt7fP">
<p><img src="https://github.com/John0Isaac/Landmark-Classification-Tagging-for-Social-Media/blob/main/static_images/icons/noun-answer-3361020.png?raw=1" alt=">" style="width:25px"/&gt; <strong>Answer:</strong> I decided to use 5 convolutional layers so that my model could be sufficiently expressive. I used dropout layers to reduce my model's tendency to overfit the training data. I made my model output a 50-dimensional vector to match with the 50 available landmark classes.</p>
</div>
<div class="cell markdown" id="myxzu0cRt7fP">
<hr />
<h2 id="-stylewidth50px-step-3-define-loss-and-optimizer"><img src="https://github.com/John0Isaac/Landmark-Classification-Tagging-for-Social-Media/blob/main/static_images/icons/noun-advance-2109145.png?raw=1" alt=">" style="width:50px"/&gt; Step 3: define loss and optimizer</h2>
<p>Open <code>src/optimization.py</code> and complete the <code>get_loss</code> function, then execute the test and make sure it passes:</p>
</div>
<div class="cell code" id="dqZuZ_sut7fQ" data-outputId="507f7775-c8fe-4ca8-d8a0-cfe829e59d54">
<div class="sourceCode" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pytest <span class="op">-</span>vv src<span class="op">/</span>optimization.py <span class="op">-</span>k get_loss</span></code></pre></div>
<div class="output stream stdout">
<pre><code>============================= test session starts ==============================
platform linux -- Python 3.7.17, pytest-7.3.2, pluggy-1.0.0 -- /usr/local/bin/python
cachedir: .pytest_cache
rootdir: /workspaces/Landmark-Classification-Tagging-for-Social-Media
plugins: anyio-3.7.0
collected 7 items / 6 deselected / 1 selected                                  

src/optimization.py::test_get_loss PASSED                                [100%]

======================= 1 passed, 6 deselected in 0.53s ========================
</code></pre>
</div>
</div>
<div class="cell markdown" id="l_PlVevIt7fQ">
<p>Then, in the same file, complete the <code>get_optimizer</code> function then execute its tests, and make sure they all pass:</p>
</div>
<div class="cell code" id="0Q3xjF-9t7fQ" data-outputId="c69e7135-85a8-4f85-c571-ee10eb308c2a">
<div class="sourceCode" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pytest <span class="op">-</span>vv src<span class="op">/</span>optimization.py <span class="op">-</span>k get_optimizer</span></code></pre></div>
<div class="output stream stdout">
<pre><code>============================= test session starts ==============================
platform linux -- Python 3.7.17, pytest-7.3.2, pluggy-1.0.0 -- /usr/local/bin/python
cachedir: .pytest_cache
rootdir: /workspaces/Landmark-Classification-Tagging-for-Social-Media
plugins: anyio-3.7.0
collected 7 items / 1 deselected / 6 selected                                  

src/optimization.py::test_get_optimizer_type PASSED                      [ 16%]
src/optimization.py::test_get_optimizer_is_linked_with_model PASSED      [ 33%]
src/optimization.py::test_get_optimizer_returns_adam PASSED              [ 50%]
src/optimization.py::test_get_optimizer_sets_learning_rate PASSED        [ 66%]
src/optimization.py::test_get_optimizer_sets_momentum PASSED             [ 83%]
src/optimization.py::test_get_optimizer_sets_weight_decat PASSED         [100%]

======================= 6 passed, 1 deselected in 0.54s ========================
</code></pre>
</div>
</div>
<div class="cell markdown" id="JmrYor3Qt7fQ">
<hr />
<h2 id="-stylewidth50px-step-4-train-and-validate-the-model"><img src="https://github.com/John0Isaac/Landmark-Classification-Tagging-for-Social-Media/blob/main/static_images/icons/noun-advance-2109145.png?raw=1" alt=">" style="width:50px"/&gt; Step 4: Train and Validate the Model</h2>
<blockquote>
<p><img src="https://github.com/John0Isaac/Landmark-Classification-Tagging-for-Social-Media/blob/main/static_images/icons/noun-info-2558213.png?raw=1" alt="?" style="width:25px"/> Testing ML code is notoriously difficult. The tests in this section merely exercise the functions you are completing, so it will help you catching glaring problems but it won't guarantee that your training code is bug-free. If you see that your loss is not decreasing, for example, that's a sign of a bug or of a flawed model design. Use your judgement.</p>
</blockquote>
<p>Open <code>src/train.py</code> and complete the <code>train_one_epoch</code> function, then run the tests:</p>
</div>
<div class="cell code" id="YvuVNX2St7fQ" data-outputId="79db3ea9-cf3e-4168-c2d6-4be86f9855b7">
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pytest <span class="op">-</span>vv src<span class="op">/</span>train.py <span class="op">-</span>k train_one_epoch</span></code></pre></div>
<div class="output stream stdout">
<pre><code>============================= test session starts ==============================
platform linux -- Python 3.7.17, pytest-7.3.2, pluggy-1.0.0 -- /usr/local/bin/python
cachedir: .pytest_cache
rootdir: /workspaces/Landmark-Classification-Tagging-for-Social-Media
plugins: anyio-3.7.0
collected 4 items / 3 deselected / 1 selected                                  

src/train.py::test_train_one_epoch PASSED                                [100%]

======================= 1 passed, 3 deselected in 9.88s ========================
</code></pre>
</div>
</div>
<div class="cell markdown" id="0MsvJCgFt7fR">
<p>Now complete the <code>valid</code> function, then run the tests:</p>
</div>
<div class="cell code" id="c2hVElRBt7fR" data-outputId="2628c81d-80ca-4928-a255-d988205b214c">
<div class="sourceCode" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pytest <span class="op">-</span>vv src<span class="op">/</span>train.py <span class="op">-</span>k valid_one_epoch</span></code></pre></div>
<div class="output stream stdout">
<pre><code>============================= test session starts ==============================
platform linux -- Python 3.7.17, pytest-7.3.2, pluggy-1.0.0 -- /usr/local/bin/python
cachedir: .pytest_cache
rootdir: /workspaces/Landmark-Classification-Tagging-for-Social-Media
plugins: anyio-3.7.0
collecting ... </code></pre>
</div>
<div class="output stream stdout">
<pre><code>collected 4 items / 3 deselected / 1 selected                                  

src/train.py::test_valid_one_epoch PASSED                                [100%]

======================= 1 passed, 3 deselected in 6.33s ========================
</code></pre>
</div>
</div>
<div class="cell markdown" id="XsILT5Wzt7fR">
<p>Now complete the <code>optimize</code> function, then run the tests:</p>
</div>
<div class="cell code" id="ukjbyNRxt7fR" data-outputId="6b3850dd-8e2a-400c-cf63-b1b9701b7276">
<div class="sourceCode" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pytest <span class="op">-</span>vv src<span class="op">/</span>train.py <span class="op">-</span>k optimize</span></code></pre></div>
<div class="output stream stdout">
<pre><code>============================= test session starts ==============================
platform linux -- Python 3.7.17, pytest-7.3.2, pluggy-1.0.0 -- /usr/local/bin/python
cachedir: .pytest_cache
rootdir: /workspaces/Landmark-Classification-Tagging-for-Social-Media
plugins: anyio-3.7.0
collected 4 items / 3 deselected / 1 selected                                  

src/train.py::test_optimize </code></pre>
</div>
<div class="output stream stdout">
<pre><code>PASSED                                       [100%]

======================= 1 passed, 3 deselected in 13.12s =======================
</code></pre>
</div>
</div>
<div class="cell markdown" id="FDqhLkXEt7fR">
<p>Finally, complete the <code>test</code> function then run the tests:</p>
</div>
<div class="cell code" id="wN63SckEt7fS" data-outputId="ddacb1dc-9890-4dee-ca52-8449383c8276">
<div class="sourceCode" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pytest <span class="op">-</span>vv src<span class="op">/</span>train.py <span class="op">-</span>k one_epoch_test</span></code></pre></div>
<div class="output stream stdout">
<pre><code>============================= test session starts ==============================
platform linux -- Python 3.7.17, pytest-7.3.2, pluggy-1.0.0 -- /usr/local/bin/python
cachedir: .pytest_cache
rootdir: /workspaces/Landmark-Classification-Tagging-for-Social-Media
plugins: anyio-3.7.0
collected 4 items / 3 deselected / 1 selected                                  

src/train.py::test_one_epoch_test PASSED                                 [100%]

======================= 1 passed, 3 deselected in 7.33s ========================
</code></pre>
</div>
</div>
<div class="cell markdown" id="oA0y69Xmt7fS">
<hr />
<h2 id="-stylewidth50px-step-5-putting-everything-together"><img src="https://github.com/John0Isaac/Landmark-Classification-Tagging-for-Social-Media/blob/main/static_images/icons/noun-advance-2109145.png?raw=1" alt=">" style="width:50px"/&gt; Step 5: Putting everything together</h2>
<p>Allright, good job getting here! Now it's time to see if all our hard work pays off. In the following cell we will train your model and validate it against the validation set.</p>
<p>Let's start by defining a few hyperparameters. Feel free to experiment with different values and try to optimize your model:</p>
</div>
<div class="cell code" data-execution_count="1" id="34GiKjrOt7fS">
<div class="sourceCode" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">64</span>        <span class="co"># size of the minibatch for stochastic gradient descent (or Adam)</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>valid_size <span class="op">=</span> <span class="fl">0.2</span>       <span class="co"># fraction of the training data to reserve for validation</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">100</span>        <span class="co"># number of epochs for training</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>num_classes <span class="op">=</span> <span class="dv">50</span>       <span class="co"># number of classes. Do not change this</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>dropout <span class="op">=</span> <span class="fl">0.4</span>          <span class="co"># dropout for our model</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.001</span>  <span class="co"># Learning rate for SGD (or Adam)</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>opt <span class="op">=</span> <span class="st">&#39;sgd&#39;</span>            <span class="co"># optimizer. &#39;sgd&#39; or &#39;adam&#39;</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>weight_decay <span class="op">=</span> <span class="fl">0.0</span>     <span class="co"># regularization. Increase this to combat overfitting</span></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="14" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:807}" id="HmCakROHt7fS" data-outputId="3f3ad3d7-654b-4fe6-cd28-1fb2ec154282">
<div class="sourceCode" id="cb32"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.data <span class="im">import</span> get_data_loaders</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.train <span class="im">import</span> optimize</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.optimization <span class="im">import</span> get_optimizer, get_loss</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.model <span class="im">import</span> MyModel</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="co"># get the data loaders using batch_size and valid_size defined in the previous</span></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="co"># cell</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="co"># HINT: do NOT copy/paste the values. Use the variables instead</span></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>data_loaders <span class="op">=</span> get_data_loaders(batch_size, valid_size)</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a><span class="co"># instance model MyModel with num_classes and drouput defined in the previous</span></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a><span class="co"># cell</span></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> MyModel(num_classes, dropout)</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the optimizer using get_optimizer and the model you just created, the learning rate,</span></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a><span class="co"># the optimizer and the weight decay specified in the previous cell</span></span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> get_optimizer(model, opt, learning_rate, weight_decay)</span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the loss using get_loss</span></span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> get_loss()</span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a>optimize(</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a>    data_loaders,</span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a>    model,</span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a>    optimizer,</span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a>    loss,</span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a>    n_epochs<span class="op">=</span>num_epochs,</span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a>    save_path<span class="op">=</span><span class="st">&quot;checkpoints/best_val_loss.pt&quot;</span>,</span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a>    interactive_tracking<span class="op">=</span><span class="va">True</span></span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="output display_data">
<p><img src="8fce315ea4eb007a5d5623a38d1250a86d34c2cd.png" /></p>
</div>
</div>
<div class="cell markdown" id="m-F8tXLvt7fS">
<hr />
<h2 id="-stylewidth50px-step-6-testing-against-the-test-set"><img src="https://github.com/John0Isaac/Landmark-Classification-Tagging-for-Social-Media/blob/main/static_images/icons/noun-advance-2109145.png?raw=1" alt=">" style="width:50px"/&gt; Step 6: testing against the Test Set</h2>
<blockquote>
<p><img src="https://github.com/John0Isaac/Landmark-Classification-Tagging-for-Social-Media/blob/main/static_images/icons/noun-info-2558213.png?raw=1" alt="?" style="width:25px"/> only run this <em>after</em> you have completed hyperpameter optimization. Do not optimize hyperparameters by looking at the results on the test set, or you might overfit on the test set (bad, bad, bad)</p>
</blockquote>
<p>Run the code cell below to try out your model on the test dataset of landmark images. Ensure that your test accuracy is greater than 50%.</p>
</div>
<div class="cell code" data-execution_count="4" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="JwYbImgLt7fS" data-outputId="c5f8eb97-a11e-4691-cbc8-dedbbd3fc17c">
<div class="sourceCode" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load the model that got the best validation accuracy</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.train <span class="im">import</span> one_epoch_test</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.model <span class="im">import</span> MyModel</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> MyModel(num_classes<span class="op">=</span>num_classes, dropout<span class="op">=</span>dropout)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="co"># YOUR CODE HERE: load the weights in &#39;checkpoints/best_val_loss.pt&#39;</span></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>model.load_state_dict(torch.load(<span class="st">&#39;checkpoints/best_val_loss.pt&#39;</span>))</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Run test</span></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>one_epoch_test(data_loaders[<span class="st">&#39;test&#39;</span>], model, loss)</span></code></pre></div>
<div class="output error" data-ename="RuntimeError" data-evalue="Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device(&#39;cpu&#39;) to map your storages to the CPU.">
<pre><code>---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
/tmp/ipykernel_13155/2160261974.py in &lt;module&gt;
      7 
      8 # YOUR CODE HERE: load the weights in &#39;checkpoints/best_val_loss.pt&#39;
----&gt; 9 model.load_state_dict(torch.load(&#39;checkpoints/best_val_loss.pt&#39;))
     10 
     11 # Run test

~/.local/lib/python3.7/site-packages/torch/serialization.py in load(f, map_location, pickle_module, **pickle_load_args)
    710                     opened_file.seek(orig_position)
    711                     return torch.jit.load(opened_file)
--&gt; 712                 return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
    713         return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
    714 

~/.local/lib/python3.7/site-packages/torch/serialization.py in _load(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)
   1044     unpickler = UnpicklerWrapper(data_file, **pickle_load_args)
   1045     unpickler.persistent_load = persistent_load
-&gt; 1046     result = unpickler.load()
   1047 
   1048     torch._utils._validate_loaded_sparse_tensors()

~/.local/lib/python3.7/site-packages/torch/serialization.py in persistent_load(saved_id)
   1014         if key not in loaded_storages:
   1015             nbytes = numel * torch._utils._element_size(dtype)
-&gt; 1016             load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
   1017 
   1018         return loaded_storages[key]

~/.local/lib/python3.7/site-packages/torch/serialization.py in load_tensor(dtype, numel, key, location)
    999         # stop wrapping with _TypedStorage
   1000         loaded_storages[key] = torch.storage._TypedStorage(
-&gt; 1001             wrap_storage=restore_location(storage, location),
   1002             dtype=dtype)
   1003 

~/.local/lib/python3.7/site-packages/torch/serialization.py in default_restore_location(storage, location)
    174 def default_restore_location(storage, location):
    175     for _, _, fn in _package_registry:
--&gt; 176         result = fn(storage, location)
    177         if result is not None:
    178             return result

~/.local/lib/python3.7/site-packages/torch/serialization.py in _cuda_deserialize(obj, location)
    150 def _cuda_deserialize(obj, location):
    151     if location.startswith(&#39;cuda&#39;):
--&gt; 152         device = validate_cuda_device(location)
    153         if getattr(obj, &quot;_torch_load_uninitialized&quot;, False):
    154             storage_type = getattr(torch.cuda, type(obj).__name__)

~/.local/lib/python3.7/site-packages/torch/serialization.py in validate_cuda_device(location)
    134 
    135     if not torch.cuda.is_available():
--&gt; 136         raise RuntimeError(&#39;Attempting to deserialize object on a CUDA &#39;
    137                            &#39;device but torch.cuda.is_available() is False. &#39;
    138                            &#39;If you are running on a CPU-only machine, &#39;

RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device(&#39;cpu&#39;) to map your storages to the CPU.
</code></pre>
</div>
</div>
<div class="cell markdown" id="yCKJAih1t7fS">
<hr />
<h2 id="-stylewidth50px-step-7-export-using-torchscript"><img src="https://github.com/John0Isaac/Landmark-Classification-Tagging-for-Social-Media/blob/main/static_images/icons/noun-advance-2109145.png?raw=1" alt=">" style="width:50px"/&gt; Step 7: Export using torchscript</h2>
<p>Great job creating your CNN models! Now that you have put in all the hard work of creating accurate classifiers, let's export it so we can use it in our app.</p>
<p>But first, as usual, we need to complete some code!</p>
<p>Open <code>src/predictor.py</code> and fill up the missing code, then run the tests:</p>
</div>
<div class="cell code" data-execution_count="1" id="mRCimw45t7fT" data-outputId="fb4d9873-adb5-41a7-bb20-425e156b0a38">
<div class="sourceCode" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pytest <span class="op">-</span>vv src<span class="op">/</span>predictor.py</span></code></pre></div>
<div class="output stream stdout">
<pre><code>============================= test session starts ==============================
platform linux -- Python 3.7.17, pytest-7.3.2, pluggy-1.0.0 -- /usr/local/bin/python
cachedir: .pytest_cache
rootdir: /workspaces/Landmark-Classification-Tagging-for-Social-Media
plugins: anyio-3.7.0
collected 1 item                                                               

src/predictor.py::test_model_construction PASSED                         [100%]

============================== 1 passed in 11.96s ==============================
</code></pre>
</div>
</div>
<div class="cell markdown" id="985yPo44t7fT">
<p>Allright, now we are ready to export our model using our Predictor class:</p>
</div>
<div class="cell code" data-execution_count="9" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}" id="zXyZG5u2t7fT" data-outputId="eda2e294-a07e-4738-de34-0029500bdbd8">
<div class="sourceCode" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">NOTE</span><span class="co">: you might need to restart the notebook before running this step</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="co"># If you get an error about RuntimeError: Can&#39;t redefine method: forward on class</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="co"># restart your notebook then execute only this cell</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.predictor <span class="im">import</span> Predictor</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.helpers <span class="im">import</span> compute_mean_and_std</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.model <span class="im">import</span> MyModel</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.data <span class="im">import</span> get_data_loaders</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>data_loaders <span class="op">=</span> get_data_loaders(batch_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a><span class="co"># First let&#39;s get the class names from our data loaders</span></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>class_names <span class="op">=</span> data_loaders[<span class="st">&quot;train&quot;</span>].dataset.classes</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Then let&#39;s move the model_transfer to the CPU</span></span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a><span class="co"># (we don&#39;t need GPU for inference)</span></span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> MyModel(num_classes<span class="op">=</span><span class="dv">50</span>, dropout<span class="op">=</span><span class="fl">0.5</span>).cpu()</span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s make sure we use the right weights by loading the</span></span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a><span class="co"># best weights we have found during training</span></span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">NOTE</span><span class="co">: remember to use map_location=&#39;cpu&#39; so the weights</span></span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a><span class="co"># are loaded on the CPU (and not the GPU)</span></span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a>model.load_state_dict(torch.load(<span class="st">&#39;checkpoints/best_val_loss.pt&#39;</span>, map_location<span class="op">=</span>torch.device(<span class="st">&#39;cpu&#39;</span>)), strict<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s wrap our model using the predictor class</span></span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a>mean, std <span class="op">=</span> compute_mean_and_std()</span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a>predictor <span class="op">=</span> Predictor(model, class_names, mean, std).cpu()</span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-30"><a href="#cb37-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Export using torch.jit.script</span></span>
<span id="cb37-31"><a href="#cb37-31" aria-hidden="true" tabindex="-1"></a>scripted_predictor <span class="op">=</span> torch.jit.script(predictor)</span>
<span id="cb37-32"><a href="#cb37-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-33"><a href="#cb37-33" aria-hidden="true" tabindex="-1"></a>scripted_predictor.save(<span class="st">&quot;checkpoints/original_exported.pt&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Reusing cached mean and std
Dataset mean: tensor([0.4638, 0.4725, 0.4687]), std: tensor([0.2697, 0.2706, 0.3017])
Reusing cached mean and std
</code></pre>
</div>
</div>
<div class="cell markdown" id="zUtGZ8T3t7fT">
<p>Now let's make sure the exported model has the same performance as the original one, by reloading it and testing it. The Predictor class takes different inputs than the non-wrapped model, so we have to use a specific test loop:</p>
</div>
<div class="cell code" data-execution_count="10" id="5Nx8mHDTt7fT">
<div class="sourceCode" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load using torch.jit.load</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>model_reloaded <span class="op">=</span>  torch.jit.load(<span class="st">&quot;checkpoints/original_exported.pt&quot;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="11" id="EOkDkN3Jt7fb">
<div class="sourceCode" id="cb40"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.predictor <span class="im">import</span> predictor_test</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>pred, truth <span class="op">=</span> predictor_test(data_loaders[<span class="st">&#39;test&#39;</span>], model_reloaded)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>100%|███████████████████████████████████████| 1250/1250 [00:29&lt;00:00, 42.60it/s]</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Accuracy: 0.0256
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>
</code></pre>
</div>
</div>
<div class="cell markdown" id="UE3y5WVHt7fb">
<p>Finally, let's have a look at the confusion matrix of the model we are going to use in production:</p>
</div>
<div class="cell code" data-execution_count="14" id="pHaeNxR7t7fc">
<div class="sourceCode" id="cb44"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.helpers <span class="im">import</span> plot_confusion_matrix</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>plot_confusion_matrix(pred, truth)</span></code></pre></div>
<div class="output display_data">
<p><img src="cd216eca48f87fbdbad7f93482ea57c72c4cde9b.png" /></p>
</div>
</div>
</body>
</html>
